Implementation Note: Unrolling Parameters from Matrices into Vectors

function [jVal, grad] = costFunction(theta)
...
optTheta = fminunc(@costFunction, initialTheta, options)

where theta and initialTheta are vectors

Neural Network (L=4):
    Θ^(1), Θ^(2), Θ^(3) are matrices Theta1, Theta2, Theta3
    D^(1), D^(2), D^(3) are gradient matrices D1, D2, D3
"Unroll" into vectors

Ex. s_1 = 10, s_2 = 10, s_3 = 1
    Θ^(1) ∈ R^(10x11), Θ^(2) ∈ R^(10x11), Θ^(3) ∈ R^(1x11)
    D^(1) ∈ R^(10x11), D^(2) ∈ R^(10x11), D^(3) ∈ R^(1x11)

    thetaVec = [Theta1(:); Theta2(:); Theta3(:)];
    DVec = [D1(:); D2(:); D3(:)];

If you want to go back to matrix representation:
    Theta1 = reshape(thetaVec(1:110), 10, 11);
    Theta2 = reshape(thetaVec(111:220), 10, 11);
    Theta3 = reshape(thetaVec(221:231), 1, 11);

Ex. D1 ∈ R^(10x6), D2 ∈ R^(1x11) and DVec = [D1(:); D2(:)];
    If you want D2 back from DVec:
    Theta2 = reshape(thetaVec(61:72), 1, 11);

-----

Example Octave code:

Theta1 = ones(10,11)
Theta2 = 2*ones(10,11)
Theta3 = 3*ones(1,11)

thetaVec = [Theta1(:); Theta2(:); Theta3(:)];
// thetaVec becomes a 231x1 vector

reshape(thetaVec(1:110), 10, 11);
reshape(thetaVec(111:22), 10, 11);
reshape(thetaVec(221:231), 1, 11);
// thetaVec gets unrolled

-----

Learning Algorithm

Have initial params Θ^(1), Θ^(2), Θ^(3)
Unroll to get initialTheta to pass to fminunc(@costFunction, initialTheta, options)

function [jVal, gradientVec] = costFunction(thetaVec)
    From thetaVec, get Θ^(1), Θ^(2), Θ^(3)
    Use FP/BP to compute D^(1), D^(2), D^(3) and J(Θ)
    Unroll D^(1), D^(2), D^(3) to get gradientVec

-----

Matrix vs. Vector

Matrix - more convenient for FP/BP
Vector - advanced optimization algorithms assume they were already unrolled

----------

Gradient Checking

BP can be difficult to implement and there are many subtle bugs that can occur
during implementation. J(Θ) may end up decreasing look like it's working as
intended, but there might be a higher level of error there compared to if you
had a bug-free BP implementation. 
Gradient checking will eliminate almost all of these problems for FP and BP.

-----

Numerical estimation of gradients

To numerically approximate the derivative of J(Θ), take θ on J(Θ) and find a
θ - ε and θ + ε, then connect the points with a line. Take the slope as an
approximation to the derivative. 

Then d/dθ J(θ) ≈ (J(θ + ε) - J(θ + ε))/(2*ε)
where ε is something tiny, like 10^-4

gradApprox = (J(theta + EPSILON) - J(theta - EPSILON)) / (2 * EPSILON);

-----

Parameter vector θ

θ ∈ R^n (where ∈ is the unrolled version of Θ^(1), Θ^(2), Θ^(3))
θ = [θ_1, θ_2, ..., θ_n]

∂/∂θ_1 J(θ) ≈ J(θ_1 + ε, θ_2, ..., θ_n) - J(θ_1 - ε, θ_2, ..., θ_n) / (2 * ε)
∂/∂θ_2 J(θ) ≈ J(θ_1, θ_2 + ε, θ_3, ..., θ_n) - J(θ_1, θ_2 - ε, θ_3, ..., θ_n) / (2 * ε)
...
∂/∂θ_n J(θ) ≈ J(θ_1, θ_2, θ_3, ..., θ_n + ε) - J(θ_1, θ_2, θ_3, ..., θ_n - ε) / (2 * ε)

EPSILON = 1e-4;
for i = 1:n,
    thetaPlus = theta;
    thetaPlus(i) = thetaPlus(i) + EPSILON;
    thetaMinus = theta;
    thetaMinus(i) = thetaMinus(i) - EPSILON
    gradApprox(i) = (J(thetaPlus) - J(thetaMinus)) / (2 * EPSILON);
end

Then check that gradApprox ≈ DVec (from BP)

-----

Implementing gradient checking:
    - implement BP to compute DVec (unrolled D^(1), D^(2), D^(3))
    - implement numerical gradient check from above to compute gradApprox
    - make sure they give similar values
    - turn off gradient checking and use BP for learning

    - be sure to disable GC before training your classifier; if you run GC on every
      iteration of GD or in the inner loop of costFunction, runtime will be very slow
      as GC is quite slow

----------

