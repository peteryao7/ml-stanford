Cost Function with Neural Networks

Neural Network (Classification)
{(x^(1), y^(1)), (x^(2), y^(2)), ..., (x^(m), y^(m))}
L total number of layers in network
s_l = # units (not counting bias unit) in layer l

Binary classification: y = 0 or 1
Only 1 output unit for binary classification: h_Θ(x) ∈ R and s_L = 1 (final layer)

Multi-class classification (K >= 3 classes): y ∈ R^K
Like the image example from last time, with vectors of K dimenstions that represent
the correct category as 1 with 0 for everything else
K output units: h_Θ(x) ∈ R^k and s_L = K

-----

Cost function is a generalization of the one from logistic regression
Instead of one compression output unit, we have K of them.

For h_Θ(x) ∈ R^K, (h_∈(x))_i = i-th output

J(Θ) = (-1/m) * [sum(i=1, m) sum(k=1, K) y_k^(i)*log(h_Θ(x^(i))_k + (1-y_k^(i))*log(1-(h_Θ(x^(i))_k))]
       + λ/(2m) * (sum(l=1, L-1) sum(i=1, s_l) sum(j=1, s_(l+1)) (Θ_j,i^(l))^2)

It looks complicated, but it's similar.
We have an additional nested summation that loops through the number of output nodes.
The regularization accounts for multiple theta matrices, where the # columns in the current
theta matrix = # nodes in the current layer (including bias unit), and the # rows in the
current theta matrix = # nodes in the next layer (excluding bias unit).

The double sum adds up the logistic regression costs calculated for each cell in the output layer.
The triple sum adds up the squares of all the individual Θs in the whole network.
The i in the triple sum doesn't refer to the i-th training example.

----------

*** Backpropagation Algorithm *** - minimizing the cost function

Want to find min Θ J(Θ) like from GD, so we need code to compute J(Θ) and ∂/∂Θ_i,j^(l) J(Θ).

-----

Gradient computation

Ex. a neural network:
s_1 = 3, s_2 = 5, s_3 = 5, s_4 = 4

Given one training example (x,y), we can apply forward propagation 
to see the output from the input:
a^(1) = x
z^(2) = Θ^(1)a^(1)
a^(2) = g(z^(2))    (add bias term a_0^(2))
z^(3) = Θ^(2)a^(2)
a^(3) = g(z^(3))    (add bias term a_0^(3))
z^(4) = Θ^(3)a^(3)
a^(4) = h_Θ(x) = g(z^(4))

To compute the derivatives (gradient computation), we use the backpropagation algorithm:

Intuition: δ_j^(l) = "error" of node j in layer l.

For each output unit (layer L = 4):
δ_j^(4) = a_j^(4) - y_j
Where a_j^(4) = h_Θ(x)_j and y_j is from our training set

δ^(3) = (Θ^(3))^T * δ^(4) .* g'(z^(3)) where g'(z^(3)) = a^(3) .* (1-a^(3))
δ^(2) = (Θ^(2))^T * δ^(3) .* g'(z^(2)) where g'(z^(2)) = a^(2) .* (1-a^(2))

We start by computing the delta term for the output layer, then we go back a layer to 
calculate the delta terms until we reach the input layer, which has no delta.

-----

Backpropagation algorithm:
Training set {(x^(1), y^(1)),..., (x^(m), y^(m))}
Set Δ_i,j^(l) = 0 (for all l, i, j)
For i = 1 to m
    Set a^(1) = x^(i)
    Perform forward propagation to compute a^(l) for l = 2,3,...,L
    Using y^(i), compute δ^(L) = a^(L) - y^(i)
    Compute δ^(L-1), δ^(L-2), ..., δ^(2)
    Δ_i,j^(l) := Δ_i,j^(l) + a_j^(l)*δ_i^(l+1) // can also be vectorized
end

For example, for 2 training examples (x^(1), y^(1)) and (x^(2), y^(2)), to compute the
gradient, you'd calculate FP using x^(1) followed by BP using y^(1), then FP using x^(2)
followed by BP using y^(2).
