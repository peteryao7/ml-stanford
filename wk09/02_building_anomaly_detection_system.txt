Developing and Evaluating an Anomaly Detection System

When developing a learning algorithm, making decisions is much easier if we have
a way of evaluating our learning algorithm, like real-number evaluation or
precision/recall.

Assume we have some labeled data, of anomalous and non-anomalous examples.
    y=0 if normal, y=1 if anomalous
Ex. aircraft engines, y=0 if they're ok, y=1 if they're flawed or strange in some way.

Training set: x^(1),x^(2),...,x^(m) (assume non-anomalous, ok if some are actually anomalous)
CV set: (x_cv^(1),y_cv^(1)),...,(x_cv^(m_cv),y_cv^(m_cv))
Test set: (x_test^(1),y_test(1)),...,(x_test(m_test),y_test(m_test))

We'll include some examples we know to be anomalous in the CV and test sets.

-----

Aircraft engines example

10000 good engines (normal)
20 flawed engines (anomalous)

Still ok if some flawed engines slipped into the 10000, but assume they're all good.

Split the good engines 60/20/20 for our data sets and include anomalies:
Training set: 6000 good engines (y=0)
    - use these 6000 engines to fit p(x) = p(x_1;μ_1,σ_1^2)...p(x_n;μ_n,σ_n^2)
CV: 2000 good engines (y=0), 10 anomalous (y=1)
Test: 2000 good engines (y=0), 10 anomalous (y=1)

Alternative (not recommended):
Training set: 6000 good engines
CV: 4000 good engines (y=0), 10 anomalous (y=1)
Test: 4000 good engines (y=0), 10 anomalous (y=1)

-----

Algorithm evaluation

Fit model p(x) on training set {x^(1),...,x^(m)}
On a CV/test example x, predict
    y = 1 if p(x) < ε (anomaly)
        0 if p(x) >= ε (normal)

For each (x_test^(i), y_test^(i)), y_test^(i) will either be 0 or 1.

Possible evaluation metrics:
    - true positive, false positive, true negative, false negative, true negative
    - precision/recall
    - F_1 score

Measuring accuracy isn't a great idea because of skewed data.

Can also use CV set to choose ε
    - try many different values of ε, then pick the one that maximizes the f-score

==================================================

Anomaly Detection vs. Supervised Learning

If we have the labeled data and know the anomalies and non-anomalies, why don't we just
use a supervised learning algorithm like logistic regression or NN to learn directly
from our labeled data to predict y=0 or y=1?

Anomaly detection
    - very small number of positive examples (y=1), like 0-20
    - large number of negative (y=0) examples
        - when we're trying to estimate p(x), we don't have a lot of negative examples to work with
    - many different types of anomalies
        - e.g. there are many ways for aircraft engines to go wrong
        - it can be hard for any algorithm to learn what the anomalies look like
    - future anomalies may look nothing like any of the anomalous examples seen so far

Supervised Learning
    - large number of positive and negative examples
        - having a small set of positive examples doesn't give much to learn for the learning algorithm
    - enough positive examples for algorithm to get a sense of what positive examples look like
    - future positive examples are likely to be similar to the ones in the training set

Ex. Spam classification
There are many different types of spam e-mails, but we usually have a large set of spam e-mails, so
we have a good idea of what they all look like already. So we still call it a supervised learning problem.

-----

More examples

Anomaly detection
    - fraud detection
        - if you're an online retailer and you have a ton of fraud cases, it's possible it could shift
          to a supervised learning problem
    - manufacturing (aircraft engines)
    - monitoring machines in a data center
Supervised learning
    - e-mail spam classification
    - weather prediction (sunny/rainy/etc.)
    - cancer classification

==================================================

Choosing What Features to Use

When applying anomaly detection, one thing that has a huge impact on how well it does is what features to use
and what features you choose to give it.

-----

In anomaly detection, we modeled the features using Gaussian distribution, with p(x_i;μ_i,σ_i^2).
You can plot the histogram of the data with hist to make sure the data looks vaguely Gaussian 
before feeding it to an anomaly detection algorithm.

However, if it looks like the data is very skewed or not Gaussian, you can use transformations
to make the data look more Gaussian. 
    - log(x) will transform a plot skewed right to look more Gaussian
        - log(x_1), log(x_2+c)
    - sqrt
    - exponent

-----

Octave example

Let x ∈ R^1000
hist(x,50) shows a plot that doesn't look Gaussian

hist(x.^0.5, 50) shifted it a bit, but doesn't look that Gaussian
hist(x.^0.05, 50) is good
xNew = x.^0.05;

hist(log(x),50) looks pretty good too
xNew = log(x);

-----

Error analysis for anomaly detection (similar to supervised learning)

Want p(x) large for normal examples x
     p(x) small for anomalous examples x

Most common problem:
    p(x) is comparable (both large) for normal and anomalous examples

Say we had a plot of data on x_1 and we draw a Gaussian distribution model based on it.
Then there's an anomaly relatively close to the middle, so it has a pretty high probability
of being normal, but the model fails to flag it as anomalous.

We can plot x_1 against a newly created feature x_2 and try to find the anomalous example with that.
Hopefully it's easier to distinguish from there.

-----

How to choose features - monitoring computers in a data center

Choose features that might take on unusually large or small values in the event of an anomaly.

You have tens of thousands of machines in a data center. You want to know if a machine is acting up
or doing something strange.
    x_1 = memory use of computer
    x_2 = number of disk accesses/sex
    x_3 = CPU load
    x_4 = network traffic

CPU load and network traffic tend to grow linearly with each other.
I'm suspecting that a machine got stuck in some infinite loop. One failure case is that the CPU load
grows, but the network traffic doesn't.

Create a new feature x_5 = CPU load / network traffic
If a machine has a large CPU load but not much network traffic, then x_5 will grow unusually high, when
normally it should be around 1.