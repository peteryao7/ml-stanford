Cost Function for Logistic Regression

If we use the same cost function for logistic regression, the output will be wavy (not convex),
    resulting in multiple local optima.

How to choose parameters θ?

J(θ) = (1/m) * sum(i=1, m) (Cost(h_θ(x^(i)), y^(i)))
Cost(h_θ(x), y) = -log(h_θ(x)) if y=1
Cost(h_θ(x), y) = -log(1-h_θ(x)) if y=0

Graph of J(θ) vs. h_θ(x):
    When y=1, graph approaches x-axis concave
    When y=0, graph approaches infinity concave
        Cost(h_θ(x),y) -> inf if y=0 and h(x) -> 1
        Cost(h_θ(x),y) -> inf if y=1 and h(x) -> 0
        Cost(h_θ(x),y) -> inf if y=1 and h(x) -> 0
        Cost(h_θ(x),y) = 0 if h_θ(x) = y

If the correct answer y is 0, then the cost function will be 0 if h also outputs 0.
    If h approaches 1, then the cost function approaches infinity.

If the correct answer y is 1, then the cost function will be 0 if h outputs 1.
    If h approaches 0, then the cost function approaches infinity.

----------

Simplified Cost Function and Gradient Descent for Logistic Regression

J(θ) = (1/m) * sum(i=1, m) (Cost(h_θ(x^(i)), y^(i)))
Cost(h_θ(x), y) = -log(h_θ(x)) if y=1
Cost(h_θ(x), y) = -log(1-h_θ(x)) if y=0

We can condense the cost function into one equation since y is only 0 or 1:

Cost(h_θ(x),y) = -y*log(h_θ(x)) - (1-y)*log(1-h_θ(x))

If y=1: Cost(h_θ(x),y) = -log(h_θ(x))
If y=0: Cost(h_θ(x),y) = -log(1-h_θ(x))

J(θ) = -(1/m) * sum(i=1, m) (-y^(i)*log(h_θ(x^(i))) - (1-y^(i))*log(1-h_θ(x^(i))))

To fit parameters θ:
min_θ J(θ)

To make a prediction given new x:
Output h_θ(x) = 1/(1+e^(-θ^T*x)) (T = transpose)

Vectorizing the cost function:
J(θ) = 1/m * (-y^T*log(h) - (1-y)^T*log(1-h))
for h = g(Xθ)

---

Gradient descent:
Take our previous equation for J(θ).

Want min_θ J(θ):
Repeat {
    θ_j := θ_j - α*(sum(i=1,m) (h_θ(x^(i)) - y^(i)) * x_j^(i))
}

^ This looks identical to linear regression, but h_θ(x) = 1/(1+e^(-θ^T*x)) (T = transpose),
where as h_θ(x) = θ^T(x) is for linear regression.

Quiz: Suppose you are running GD to fit a logistic regression model with 
parameter θ ∈ R^(n+1). To make sure the learning rate α is set properly, 
plot the simplified cost function as a function of the number of iterations
and make sure J(θ) is decreasing on every iteration.

Quiz: To vectorize θ := θ - αδ for some vector δ ∈ R^(n+1), we should use the form
θ := θ - α*(1/m)*(sum(i=1, m) (h_θ(x^(i)) - y^(i) * x^(i)))

----------

Advanced Optimization - faster ways of optimizing θ

Optimizing logistic regression to run much more quickly than it's possible with GD,
and scaling the machine to bigger ML problems with more features.

With cost function J(θ), we want min_θ J(θ).
Given θ, we can compute J(θ) and δ/(δθ_j)*J(θ) for j = 0,1,2,...,n

For GD:
Repeat {
    θ_j := θ_j - α*δ/(δθ_j)*J(θ)
}

But there are different algorithms for optimizing min_θ like GD:
    - conjugate gradient
    - BFGS
    - L-BFGS

These algorithms are more complex, but we don't need to pick a learning rate α
and are often faster at converging than GD. 

Octave has built-in libraries that have implementations for these algorithms, and
some are more efficient than others.

Ex.

θ = [θ_1]
    [θ_2]

J(θ) = (θ_1 - 5)^2 + (θ_2 - 5)^2
δ/(δθ_1) J(θ) = 2(θ_1-5)
δ/(δθ_2) J(θ) = 2(θ_2-5)

---

function [jVal, gradient] = costFunction(theta)
    jVal = (theta(1)-5)^2 + (theta(2)-5)^2;
    gradient = zeros(2,1);
    gradient(1) = 2 * (theta(1) - 5);
    gradient(2) = 2 * (theta(2) - 5);

    options = optimset('GradObj', 'on', 'MaxIter', 100); // 100 iterations
    initialTheta = zeros(2,1); 
    [optTheta, functionVal, exitFlag] = fminuc(@costFunction, initialTheta, options);

optTheta = 5.000
           5.000

functionVal = 1.5777e-030
exitFlag = 1


    fminunc() - optimization algorithm, in our case the cost function
    optimset() - creates an object containing the options we want to send to fminunc()

(initialTheta ∈ R^d for d >= 2)
(@ - pointer to costFunction)
(help for info on functions)

---

Applying this to logistic regression

theta = [θ_0]
        [θ_1]
        [...]
        [θ_n]

function [jVal, gradient] = costFunction(theta)
    jVal = code to compute J(θ);
    gradient(1) = code to compute δ/(δθ_0) J(θ);
    gradient(2) = code to compute δ/(δθ_1) J(θ);
    ...
    gradient(n+1) = code to compute δ/(δθ_n) J(θ);